{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup library imports\n",
    "import io, time, json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "\n",
    "# import yelp client library\n",
    "from yelp.client import Client\n",
    "from yelp.oauth1_authenticator import Oauth1Authenticator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def authenticate(config_filepath):\n",
    "    \"\"\"\n",
    "    Create an authenticated yelp-python client.\n",
    "\n",
    "    Args:\n",
    "        config_filepath (string): relative path (from this file) to a file with your Yelp credentials\n",
    "\n",
    "    Returns:\n",
    "        client (yelp.client.Client): authenticated instance of a yelp.Client\n",
    "    \"\"\"\n",
    "    \n",
    "    creds = json.load(open(config_filepath))\n",
    "    auth = Oauth1Authenticator(**creds)\n",
    "    return Client(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yelp_search(client, query):\n",
    "    \"\"\"\n",
    "    Make an authenticated request to the Yelp API.\n",
    "\n",
    "    Args:\n",
    "        query (string): Search term\n",
    "\n",
    "    Returns:\n",
    "        total (integer): total number of businesses on Yelp corresponding to the query\n",
    "        businesses (list): list of yelp.obj.business.Business objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Write solution here\n",
    "    res = client.search(query)\n",
    "    return (res.total, res.businesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_restaurants(client, query, food):\n",
    "    \"\"\"\n",
    "    Retrieve ALL the restaurants on Yelp for a given query.\n",
    "\n",
    "    Args:\n",
    "        query (string): Search term\n",
    "\n",
    "    Returns:\n",
    "        results (list): list of yelp.obj.business.Business objects\n",
    "    \"\"\"\n",
    "    B = []\n",
    "    while 1:\n",
    "        try:\n",
    "            res = client.search(query,**{\"category_filter\":food,\"offset\" : len(B)})\n",
    "            if not res.businesses:\n",
    "                return B\n",
    "            B += res.businesses\n",
    "#            time.sleep(.1)\n",
    "        except:\n",
    "            return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cities_info(client, food, cities):\n",
    "    d = {}\n",
    "    for city in cities:\n",
    "        print \"requesting: \", city,\n",
    "        d[\"%s_%s\"%(city,food)] = all_restaurants(client,city,food)\n",
    "        print \": done\"\n",
    "    #d = {(\"%s_%s\"%(city,food)):all_restaurants(client,city,food) for city in cities}\n",
    "    valids = filter(lambda x: len(d[x]) >= 10, d)\n",
    "    res = {v:d[v] for v in valids}\n",
    "    return res\n",
    "\n",
    "def get_all_cities():\n",
    "    with open(\"cities.txt\",'r') as f:\n",
    "        lines = map(lambda l: \", \".join(l.rstrip().split(\"\\t\")[1:3]),f.readlines())\n",
    "        return lines\n",
    "    \n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "def save_pickle(filename, data):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "def get_city_data(data, city, foodtype):\n",
    "    '''returns dictionary:\n",
    "        avg_review\n",
    "        num_restaurants\n",
    "        city\n",
    "    '''\n",
    "    result = {}\n",
    "    key = \"%s_%s\"%(city,foodtype)\n",
    "    info = data[key]\n",
    "    result[\"num_restaurants\"] = len(info)\n",
    "    result[\"avg_review\"] = sum(map(lambda x: x.rating, info))/float(len(info))\n",
    "    return result\n",
    "    \n",
    "def get_all_city_data(data):\n",
    "    result = {}\n",
    "    for city_food in data:\n",
    "        city = city_food.split(\"_\")[0]\n",
    "        foodtype = city_food.split(\"_\")[1]\n",
    "        result[city] = get_city_data(data,city,foodtype)\n",
    "    return result\n",
    "\n",
    "def clean_business(b):\n",
    "    valids = [\"categories\", \"location\", \"name\", \"rating\", \"review_count\",\"url\"]\n",
    "    return {x : b.__dict__[x] for x in valids}\n",
    "    \n",
    "    \n",
    "def clean_data(data):\n",
    "    new_data = {}\n",
    "    for city in data:\n",
    "        new_data[city] = map(clean_business, data[city])\n",
    "    return new_data\n",
    "\n",
    "def add_feature_info(data, offset):\n",
    "    c = offset+1\n",
    "    for d in data[offset:]:\n",
    "        print \"%d of %d\"%(c,len(data))\n",
    "        features = scrapeYelpFeatures(d[\"url\"])\n",
    "        d.update(features)\n",
    "        c += 1\n",
    "        \n",
    "def get_feature_set(datalist):\n",
    "    features = set()\n",
    "    for f in datalist:\n",
    "        features |= set(f)\n",
    "    return features\n",
    "\n",
    "def fix_features(datalist):\n",
    "    features = get_feature_set(datalist)\n",
    "    for d in datalist:\n",
    "        for f in features:\n",
    "            if f not in d:\n",
    "                d[f] = None\n",
    "\n",
    "def get_random_data(data, n):\n",
    "    datalist = []\n",
    "    for d in data:\n",
    "        datalist += data[d]\n",
    "    return random.sample(datalist,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_html(url):\n",
    "    html = requests.get(url)\n",
    "    return (html.status_code, html.content)\n",
    "\n",
    "# Gets restaurant features from yelp html given a url for a restaurants page\n",
    "# returns a dictionary of the available features on the page (keys) with their \n",
    "# corresponding values\n",
    "def scrapeYelpFeatures(url):\n",
    "    (yolo, html) = retrieve_html(url)\n",
    "    \n",
    "    try:\n",
    "        imgs =  re.search(r\"See all [0-9]+\", html).group()\n",
    "        imgs = [int(s) for s in imgs.split() if s.isdigit()][0]\n",
    "    except:\n",
    "        imgs = 0\n",
    "    root = BeautifulSoup(html, \"html.parser\")\n",
    "    s = root.findAll(\"div\", {'class' : 'ywidget'}) #, { \"class\" : \"review review--with-sidebar\" })\n",
    "    #s = root.find(\"h3\", {'name': 'More business info'})\n",
    "    \n",
    "    biz_features = {\"number_of_images\" : imgs}\n",
    "    for i in s:\n",
    "        h3_elem = i.find(\"h3\")\n",
    "        if h3_elem != None:\n",
    "            if 'More business info' in h3_elem:\n",
    "                biz_attr = i.find('ul', {'class' : 'ylist'}).findAll('dt', {'class' : 'attribute-key'})\n",
    "                biz_val = i.find('ul', {'class' : 'ylist'}).findAll('dd')\n",
    "\n",
    "                for (l,r) in zip(biz_attr, biz_val):\n",
    "                    #print l.next_element.strip(), '====', r.next_element.strip()\n",
    "                    biz_features[l.next_element.strip()] = r.next_element.strip()\n",
    "    return biz_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info = load_pickle(\"Anaheim, California features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = authenticate(\"config_secret.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datalist = data['Anaheim, California'][:]\n",
    "#print datalist[999]\n",
    "#add_feature_info(datalist,268)\n",
    "#save_pickle(\"Anaheim, California features.pkl\", datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_pickle(\"Anaheim, California features.pkl\", datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_pickle(\"cities_all_restaurants_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datalist = get_random_data(data,50000)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_feature_info(datalist,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pickle(\"random.pkl\", datalist[25000:25000+12500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
