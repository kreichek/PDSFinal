{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info = load_pickle(\"Anaheim, California features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(svm, X, y):\n",
    "    preds = svm.predict(X)\n",
    "    wrong = 0\n",
    "    dist = 0\n",
    "    for (p,l) in zip(preds,y):\n",
    "        if int(p) != int(l):\n",
    "            wrong += 1\n",
    "            dist += abs(l-p)/2.0\n",
    "    print \"correct predictions: %f%%\"%(wrong/float(len(y)))\n",
    "    print \"average error: %f\"%(dist/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toBinary(s):\n",
    "    return 0 if s == None else (1 if s.lower() == 'yes' else 0)\n",
    "\n",
    "# Input is a list of dictionarys mapping features to values (defined in pickle) \n",
    "def transform_to_XY(info):\n",
    "    X = []\n",
    "    Y = []\n",
    "    feature_names = [i for i in info[0].keys()]\n",
    "    total_vals = {}\n",
    "    for x in feature_names:\n",
    "        total_vals[x] = set()\n",
    "    \n",
    "    to_ignore = set(['name', 'review_count', 'rating', 'location', 'categories', 'url', 'number_of_images', 'parking', 'Best Nights','Good For'])\n",
    "    \n",
    "    for res in info:\n",
    "        for k,v in res.items():\n",
    "            if k not in to_ignore: # Some features are of list type or already floats, or not primitive types\n",
    "                total_vals[k].add(v)\n",
    "    \n",
    "    #print total_vals\n",
    "    feature_value_map = {}\n",
    "    for k,v in total_vals.items():\n",
    "        z = 0\n",
    "        feature_value_map[k] = {}\n",
    "        for value in v:\n",
    "            feature_value_map[k][value] = z\n",
    "            z += 1\n",
    "            \n",
    "    features = deepcopy(info)\n",
    "    for b in features:\n",
    "        for f in to_ignore:\n",
    "            b.pop(f, None)\n",
    "        for f in b:\n",
    "            if f not in to_ignore and f in feature_value_map and b[f] in feature_value_map[f]:\n",
    "                b[f] = feature_value_map[f][b[f]]\n",
    "    features = [[d[f] for f in sorted(d.keys())] for d in features]\n",
    "    return (features, [f[\"rating\"]*2 for f in info])\n",
    "\n",
    "(X,y) = transform_to_XY(info)\n",
    "clf = svm.SVC(kernel='rbf', tol=0.001, verbose=True)\n",
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.  9.  9.  8.  8.  8.  9.  8.  9.  9.  8.  9.  9.  8.  8.  8.  8.  8.\n",
      "  8.  9.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.\n",
      "  8.  7.  8.  8.  8.  9.  8.  8.  8.  7.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  9.  8.  8.  7.  8.  8.  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  7.  8.  8.  8.  8.  7.  8.  8.  8.  9.  8.  9.  8.  8.  8.  8.  8.  7.\n",
      "  8.  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  9.  9.  9.  8.  8.  8.  9.  9.  8.  8.  8.  7.  8.  8.  8.\n",
      "  8.  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  7.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.\n",
      "  8.  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  7.  8.  8.  8.  8.  8.\n",
      "  6.  8.  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  9.  7.  8.  9.  8.  8.  8.  9.  7.  8.  8.  8.  8.  8.  8.  8.  9.\n",
      "  8.  8.  8.  8.  8.  8.  6.  8.  8.  8.  6.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  7.  8.  7.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.\n",
      "  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  6.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  6.  8.  8.  8.  8.  8.  8.  8.  8.  7.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  9.  8.  8.  9.  8.  8.  8.  8.  8.  8.  8.  6.\n",
      "  8.  8.  8.  8.  8.  8.  8.  6.  8.  9.  8.  8.  8.  9.  8.  8.  8.  8.\n",
      "  8.  7.  6.  8.  8.  8.  8.  8.  8.  9.  6.  8.  8.  8.  8.  8.  8.  9.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  9.  8.  8.  8.  6.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  9.  8.  8.  8.  6.  8.  8.  8.  8.  8.  6.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  7.  8.\n",
      "  8.  9.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  6.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  7.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  6.  9.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  6.  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  6.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  9.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.  8.  9.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  6.  8.  8.  8.  8.  8.  8.  8.  8.  9.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  7.  8.\n",
      "  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  7.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  7.  9.  8.  6.  8.  8.  9.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.  9.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  7.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  9.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  9.  8.  8.  8.  6.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.]\n",
      "correct predictions: 0.539000%\n",
      "average error: 0.403000\n"
     ]
    }
   ],
   "source": [
    "accuracy(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
